{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5a1575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tweepy\n",
    "\n",
    "from utils import build_df, get_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1c166-2aae-42a1-8e80-81f605845ae7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data processing notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360607d-5083-4732-83c7-7bd38e0b3bdf",
   "metadata": {},
   "source": [
    "This notebook describes how to get from the tweet IDs provided by [Banda et al.](https://github.com/thepanacealab/covid18_twitter) to the network presented in our paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bc660-2406-4792-9661-05e5b07e1791",
   "metadata": {},
   "source": [
    "We hydrated the tweet IDs using `hydrator.py` with the command below for every month of 2021:\n",
    "\n",
    "```sh\n",
    "python hydrator.py -m <month> -y <year> -t <BEARER TOKEN> -c  \n",
    "```\n",
    "```sh\n",
    "  -h   show this help message and exit\n",
    "  -m   month (number) for which the data should be hydrated\n",
    "  -y   year (number) for which the data should be hydrated\n",
    "  -c   whether or not to hydrate clean data (without retweets)\n",
    "  -t   Twitter API Bearer Token\n",
    "```\n",
    "\n",
    "The hydrated data would then be found under `data/clean/de/hydrated/csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd3a03e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# build tweets dataframe\n",
    "\n",
    "tweets_df = build_df(\"data/clean/de/hydrated/csv\", \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6cee64-14f9-4e72-87a2-7a22677588b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# remove username's with tweets in languages other the German from the dataset\n",
    "\n",
    "tweets_df = tweets_df[tweets_df[\"username\"] != \"benshapiro\"]\n",
    "tweets_df = tweets_df[tweets_df[\"username\"] != \"mir_ocall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec06eb78-d80c-47d2-b3b8-7590f440c24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# hydrate user_ids\n",
    "\n",
    "all_user_ids = list(tweets_df[\"author_id\"].drop_duplicates())\n",
    "users = get_users(all_user_ids, bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2a3975-83ac-4f02-8f23-4c37f41b9296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# create pandas dataframe of users\n",
    "\n",
    "users_df = pd.DataFrame(data=users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f5c1a7-01c8-4b61-816a-dca6c96f4f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# add month and year column to the dataframe\n",
    "\n",
    "months = pd.DatetimeIndex(tweets_df[\"created_at\"]).month\n",
    "tweets_df[\"month\"] = months.apply(lambda x: calendar.month_abbr[x])\n",
    "tweets_df[\"year\"] = pd.DatetimeIndex(tweets_df[\"created_at\"]).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "770a1e3c-26dd-44b2-8ecc-0f2350410add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# add user meta data to tweets dataframe\n",
    "\n",
    "tweets_df = tweets_df.merge(\n",
    "    users_df[[\"id\", \"name\", \"username\"]],\n",
    "    left_on=\"author_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "tweets_df.drop(columns=[\"id_y\"], inplace=True)\n",
    "tweets_df.rename(columns={\"id_x\": \"tweet_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9752065c-a0ae-45c7-8463-4274046db5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# compute tweet popularity\n",
    "# popularity = like_count + retweet_count + reply_count + quote_count\n",
    "\n",
    "tweets_df[\"tweet_popularity\"] = df.loc[\n",
    "    :, [\"like_count\", \"retweet_count\", \"reply_count\", \"quote_count\"]\n",
    "].sum(axis=1)\n",
    "\n",
    "tweets_df.sort_values(\"tweet_popularity\", ascending=False, inplace=True)\n",
    "tweets_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c437393d-a0ac-444c-8032-8bf7db37e4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# save users df to users.csv and tweets data frame augemented with user info to tweets.csv\n",
    "\n",
    "users_df.to_csv(\"data/users.csv\", index=False)\n",
    "tweets_df.to_csv(\"data/tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b194a645-af3a-4d94-8ca5-2ef006441de3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Read-in the saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff9eab32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"data/tweets.csv\", encoding=\"utf-8\")\n",
    "users_df = pd.read_csv(\"data/users.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117240ff-efa9-45ee-b005-22f5f1d56831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# get their followers and save them in the followings dictionary.\n",
    "\n",
    "# replace bearer token with your twitter API token\n",
    "client = tweepy.Client(\n",
    "    bearer_token=\"AAAAAAAAAAAAAAAAAAAAAF7uPAEAAAAAbtQx0EP7VaaPPUT%2FEFxvIxFtGZ8%3DXAQkzZPA8sVZ8qu0Vx9lWeqP2CxkAFs6qjQGzUondvLqWEZHLL\",\n",
    "    wait_on_rate_limit=True,\n",
    ")\n",
    "\n",
    "followings = {}\n",
    "\n",
    "for _, user in top_tweets_users_1000.iterrows(): # biggest network\n",
    "    friends = []\n",
    "    for u in tweepy.Paginator(\n",
    "        client.get_users_following, id=user[\"id\"], max_results=1000\n",
    "    ).flatten(limit=1000):\n",
    "        friends.append({\"id\": u.id, \"username\": u.username})\n",
    "    followings[user[\"username\"]] = {\"id\": user[\"id\"], \"friends\": friends}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "650cec6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# save followings object\n",
    "\n",
    "with open(\"data/objects/followings\", \"wb\") as f:\n",
    "    pickle.dump(followings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd1dd878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load followings object\n",
    "\n",
    "followings = {}\n",
    "with open(\"data/objects/followings\", \"rb\") as openfile:\n",
    "    followings = pickle.load(openfile)\n",
    "len(followings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6604795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def friend_filter(ar, df):\n",
    "    x = [n for n in ar if n[\"username\"] in list(df[\"username\"])]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e85e0f-42d9-442e-9f2d-766212c4077d",
   "metadata": {},
   "source": [
    "### Build edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c4503be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_graph(edges_path, df, followings_filtered):\n",
    "    header = [\"source\", \"target\"]\n",
    "    with open(edges_path, \"w\", encoding=\"UTF8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for username, d in followings_filtered.items():\n",
    "            for friend in d[\"friends\"]:\n",
    "                row = [str(username), str(friend[\"username\"])]\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22c0001e-9619-4eee-a596-d670b00b6236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511\n",
      "1024\n",
      "905\n",
      "745\n",
      "627\n",
      "557\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "# one loop to rule them all:\n",
    "for threshold in [1000, 2000, 2200, 2500, 2800, 3000, 4000]:\n",
    "    top_tweets = tweets_df.query(\"tweet_popularity>=@threshold\")\n",
    "    # share of tweets per top user\n",
    "    _ = top_tweets.groupby([\"username\"], as_index=False).size()\n",
    "    top_tweets_usernames = _.sort_values(\"size\", ascending=False).reset_index(drop=True)\n",
    "    # get the users associated with these tweets\n",
    "    top_tweets_users = top_tweets_usernames.merge(users_df, on=\"username\", how=\"left\")\n",
    "    print(len(top_tweets))\n",
    "\n",
    "    # filtered friends list, only use friends that belong those who authored the top 1024 tweets\n",
    "    followings_filtered = {\n",
    "        key: {\n",
    "            \"id\": value[\"id\"],\n",
    "            \"friends\": friend_filter(value[\"friends\"], top_tweets_users),\n",
    "        }\n",
    "        for key, value in followings.items()\n",
    "        if key in list(top_tweets_users[\"username\"])\n",
    "    }\n",
    "\n",
    "    edges_path = f\"data/networks/network_edgelist_{threshold}.csv\"\n",
    "    build_graph(edges_path, top_tweets_users, followings_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43478a52-e862-4318-91ff-fbf532286a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/networks/network_edgelist_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e29883b-2883-455a-a581-d065077ba430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.query(\"source!=target\").reset_index(drop=True).to_csv(\n",
    "    \"data/networks/network_edgelist_1000.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
